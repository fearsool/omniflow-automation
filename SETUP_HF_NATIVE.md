# ğŸ­ OmniFlow - HuggingFace Native Automation Factory

**0 Maliyet | HatasÄ±z | Paralel 25-40 Ajan | Production Ready**

---

## ğŸ“‹ Genel BakÄ±ÅŸ

OmniFlow artÄ±k **tamamen Ã¼cretsiz HuggingFace API** ve **Ollama local modellerle** Ã§alÄ±ÅŸÄ±yor. Gemini'ye ihtiyaÃ§ yok. Her otomasyon sorunsuz ÅŸekilde Ã§alÄ±ÅŸÄ±r, 3 kez otomatik retry, timeout korumasÄ± ve exponential backoff ile.

### âœ… Ã–zellikler

- **0 Maliyet**: Free HF API + Ollama lokal modeller
- **HatasÄ±z**: 3x retry, exponential backoff, timeout protection
- **Paralel**: 25-40 ajan aynÄ± anda (worker pool + priority queue)
- **Persistent**: SQLite database ile execution history
- **MonitÃ¶rlÃ¼**: Health checks, memory management, logging
- **Notifikasyonlu**: Telegram + Discord bildirimler
- **Production Ready**: Python/Node.js/Docker/GitHub Actions exports

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. HuggingFace Token OlmasÄ±

```bash
# 1. https://huggingface.co/settings/tokens adresine git
# 2. "New token" â†’ "Fine-grained" seÃ§
# 3. Name: "omniflow"
# 4. Scopes: "Read" seÃ§
# 5. Create â†’ Token'Ä± kopyala
```

### 2. Ã‡evre DeÄŸiÅŸkenlerini Ayarla

```bash
# .env dosyasÄ± oluÅŸtur
cp .env.example .env

# DÃ¼zenle:
HUGGINGFACE_TOKEN=hf_your_token_here
USE_OLLAMA=false  # BaÅŸlangÄ±Ã§ta HF API kullan
REQUEST_TIMEOUT=300
MAX_RETRIES=3
```

### 3. Test Et

**Browser'da:**
```bash
npm install
npm run dev
# http://localhost:5173 aÃ§Ä±
# Test deÄŸiÅŸkenleri ekle
# "Sandbox Test" butonuna tÄ±kla
```

**CLI'da:**
```bash
python runner.py
```

---

## ğŸ—ï¸ MimarÄ±

### Frontend (App.tsx)

```typescript
// HuggingFace ile node Ã§alÄ±ÅŸtÄ±r
const result = await callHuggingFaceModel({
  task: prompt,
  model: selectBestModel(nodeType),
  timeout: 300000,  // 5 dakika
  useOllama: false,
});
```

**Worker Pool (agentQueueService.ts):**
- 25-40 worker (CPU core'u kadar)
- Priority queue (critical â†’ normal â†’ low)
- Health checks (10s interval)
- Memory management

### Backend (runner.py)

```python
# Supabase'den aktif blueprint'leri Ã§ek
# Her birini HF API ile Ã§alÄ±ÅŸtÄ±r
# SQLite'a kaydet
# Telegram/Discord'a bildir
```

**Retry Logic:**
- Attempt 1: 1 saniye
- Attempt 2: 2 saniye
- Attempt 3: 4 saniye
- Max total: 7 saniye

**Model Loading Handling:**
```python
# Model yÃ¼kleniyor = wait 30s â†’ retry
# Rate limit = wait 60s â†’ retry
# Timeout = retry 3x
```

---

## ğŸ“¦ Kurulum SeÃ§enekleri

### SeÃ§enek 1: Local (Hemen Test Etmek)

```bash
# 1. Frontend
npm install
npm run dev

# 2. Runner (baÅŸka terminal)
python runner.py

# 3. Ollama (opsiyonel - lokal modeller iÃ§in)
ollama serve
```

### SeÃ§enek 2: Docker (Production)

```bash
# Kurulum
docker-compose up -d

# Logs
docker-compose logs -f omniflow-runner

# Durdurmak
docker-compose down
```

**Compose dosyasÄ±:**
- `omniflow-runner`: Python automation runner
- `ollama`: Local model server (optional)

### SeÃ§enek 3: GitHub Actions (Scheduled)

```bash
# 1. GitHub Secrets ekle:
HUGGINGFACE_TOKEN=hf_...
SUPABASE_URL=https://...
SUPABASE_KEY=eyJ...
TELEGRAM_BOT_TOKEN=123...
DISCORD_WEBHOOK=https://...

# 2. .github/workflows/omniflow-runner-hf.yml otomatik Ã§alÄ±ÅŸÄ±r
# Her 6 saatte bir
```

### SeÃ§enek 4: Railway/Render (Free Cloud)

```bash
# Railway (en kolayÄ±)
1. https://railway.app adresine git
2. New Project â†’ GitHub repo baÄŸla
3. Environment variables ekle
4. Deploy

# Variables:
HUGGINGFACE_TOKEN=hf_...
SUPABASE_URL=...
USE_OLLAMA=false
```

---

## ğŸ”§ Kod Ãœretimi

**Blueprint'ten otomatik kod oluÅŸtur:**

```typescript
import { generateCode } from './services/codeGeneratorHF';

// Python script
const pythonCode = generateCode(blueprint, 'python');
// â†’ main.py, requirements.txt, .env.example, Dockerfile, docker-compose.yml

// Node.js
const nodeCode = generateCode(blueprint, 'nodejs');
// â†’ main.js, package.json, .env.example

// GitHub Action
const actionCode = generateCode(blueprint, 'github-action');
// â†’ .github/workflows/automation-name.yml
```

**Ã‡Ä±kan kod:**
- âœ… HuggingFace API entegre
- âœ… 3x retry logic
- âœ… SQLite persistence
- âœ… Timeout koruma
- âœ… Error handling
- âœ… Ready to run

---

## ğŸ“Š Monitoring

### Database Sorgusu

```bash
# SQLite'a bak
sqlite3 automation_runner.db

# TÃ¼m executions
SELECT blueprint_name, status, total_time_ms 
FROM runner_executions 
ORDER BY started_at DESC 
LIMIT 10;

# BaÅŸarÄ±sÄ±z runs
SELECT * FROM runner_executions WHERE status = 'error';
```

### Logs

```bash
# Python runner
python runner.py 2>&1 | grep "HF\|HATA\|âœ“"

# Docker
docker-compose logs omniflow-runner

# GitHub Actions
GitHub repo â†’ Actions â†’ Run details
```

---

## ğŸ§ª Test SenaryolarÄ±

### 1. HuggingFace API Test

```python
from services.huggingfaceService import callHuggingFaceModel

result = await callHuggingFaceModel({
    'task': 'Merhaba, sen kimsin?',
    'model': 'mistralai/Mistral-7B-Instruct-v0.2',
    'timeout': 300000,
})

print(result.output)  # Should work âœ…
```

### 2. Queue Test (40 Agent)

```typescript
import { agentQueue } from './services/agentQueueService';

// 40 task ekle
const taskIds = [];
for (let i = 0; i < 40; i++) {
  const id = agentQueue.addTask({
    blueprintId: 'test',
    priority: i % 2 === 0 ? 'high' : 'normal',
    payload: { test: true },
  });
  taskIds.push(id);
}

// Bekle ve sonuÃ§ al
const results = await agentQueue.waitForTasks(taskIds);
console.log(`${results.size} tasks completed`);
```

### 3. Failure Simulation

```typescript
selectedBlueprint.testConfig = {
  variables: [
    { key: 'TEST', value: 'value' }
  ],
  simulateFailures: true  // â† 30% hata oranÄ±
};

// Sandbox Test baÅŸlat
// Yapay hatalar ve recover'Ä± gÃ¶zle
```

---

## ğŸš¨ Sorun Giderme

### "Token not found"

```
âŒ HUGGINGFACE_TOKEN bulunamadÄ±

Ã‡Ã¶zÃ¼m:
1. https://huggingface.co/settings/tokens adresine git
2. Token oluÅŸtur
3. .env dosyasÄ±na ekle: HUGGINGFACE_TOKEN=hf_...
4. UygulamayÄ± restart et
```

### "Model loading"

```
â³ Model yÃ¼kleniyor, 30s bekleniyor...

Bu normal! Ä°lk Ã§aÄŸrÄ± model'i yÃ¼kler.
Otomatik retry 3 kez denecek.
Max 90 saniyede tamamlanacak.
```

### "Rate limit"

```
â³ Rate limited, 60s bekleniyor...

Ã‡Ã¶zÃ¼m: REQUEST_TIMEOUT'u artÄ±r
Veya USE_OLLAMA=true (lokal model)
```

### "Timeout"

```
ERROR: Task timeout after 300000ms

Ã‡Ã¶zÃ¼m: .env dosyasÄ±nda REQUEST_TIMEOUT deÄŸerini artÄ±r
REQUEST_TIMEOUT=600  # 10 dakika
```

### "Ollama connection failed"

```
OLLAMA_URL: http://localhost:11434

Ã‡Ã¶zÃ¼m:
1. Ollama'yÄ± baÅŸlat: ollama serve
2. Veya docker-compose up ollama
3. Veya USE_OLLAMA=false (HF API kullan)
```

---

## ğŸ“ˆ Performance Tuning

### 1. Parallelism

```typescript
// agentQueueService.ts
const CONCURRENCY = Math.min(navigator.hardwareConcurrency || 4, 40);
// â†’ Auto-adjust to CPU cores (max 40)
```

### 2. Memory Management

```python
# runner.py
MEMORY_THRESHOLD_MB = 500
# â†’ Worker'lar 500MB'Ä± aÅŸarsa garbage collection trigger
```

### 3. Timeout AyarlanmasÄ±

```bash
# Local (fast internet)
REQUEST_TIMEOUT=60

# Cloud (slow/unpredictable)
REQUEST_TIMEOUT=300

# Very slow (3G/satellite)
REQUEST_TIMEOUT=600
```

### 4. Model Selection

```python
# Fast inference (1-2 sec)
'mistralai/Mistral-7B-Instruct-v0.2'

# Better quality (3-5 sec)
'meta-llama/Llama-2-7b-chat-hf'

# Powerful (5-10 sec)
'meta-llama/Meta-Llama-3-8B-Instruct'

# Local Ollama (instant)
'mistral' or 'neural-chat'
```

---

## ğŸ¯ Best Practices

1. **Her zaman retry logic'i test et**
   ```bash
   TEST_FAILURES=true npm run test
   ```

2. **Database'i dÃ¼zenli backup'la**
   ```bash
   cp automation_runner.db automation_runner_backup.db
   ```

3. **Logs'u kontrol et**
   ```bash
   # BaÅŸarÄ±sÄ±z runs bul
   grep "âŒ" logs.txt
   ```

4. **Memory leak kontrolÃ¼**
   ```typescript
   // Browser DevTools â†’ Memory â†’ Take heap snapshot
   // Her 100 task sonra memory kontrol et
   ```

5. **Rate limit'i respektleyin**
   ```python
   time.sleep(1)  # Node'lar arasÄ±nda
   ```

---

## ğŸ“š API Referensi

### HuggingFaceService

```typescript
callHuggingFaceModel({
  task: string,           // Model iÃ§in prompt
  model?: string,         // HF model ID (default: Mistral)
  temperature?: number,   // 0.0-1.0 (default: 0.7)
  maxTokens?: number,     // Max output length
  timeout?: number,       // Ms (default: 300000)
  useOllama?: boolean,    // Try Ollama first
}): Promise<HFResponse>

// Returns:
{
  success: boolean,
  output?: string,
  error?: string,
  model: string,
  tokensUsed?: number,
  cached?: boolean,
}
```

### AgentQueueService

```typescript
agentQueue.addTask(task)              // â†’ taskId
agentQueue.addBatch(tasks)            // â†’ taskIds[]
agentQueue.waitForTasks(ids)          // â†’ Promise<Map>
agentQueue.getStats()                 // â†’ QueueStats
agentQueue.retryFailedTasks()         // â†’ count
agentQueue.on('task-completed', fn)   // â†’ unsubscribe()
```

---

## ğŸŒ Deployment Checklist

- [ ] HuggingFace token oluÅŸturdum
- [ ] .env dosyasÄ±nÄ± oluÅŸturdum
- [ ] Local'de test ettim (`npm run dev`)
- [ ] `runner.py` baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±
- [ ] SQLite database oluÅŸturdu
- [ ] Docker image build ettim (`docker build -f Dockerfile.runner .`)
- [ ] GitHub Secrets ekledim
- [ ] Supabase blueprints setup'Ä±nÄ± yaptÄ±m
- [ ] Telegram/Discord webhook'larÄ±nÄ± kurdum
- [ ] Production'a deploy ettim

---

## ğŸ†˜ Destek

**Sorular:**
- GitHub Issues aÃ§mak
- Logs'u share etmek (sensitive data hariÃ§)
- SQLite database'i analiz etmek

**Rapor etmek:**
- Hata mesajÄ±nÄ± tam yaz
- `DB_FILE` iÃ§eriÄŸini share et (tablolar)
- Ã‡evre ayarlarÄ±nÄ± (token hariÃ§) paylaÅŸ

---

**Made with â¤ï¸ for 0-cost, fault-tolerant automation**
